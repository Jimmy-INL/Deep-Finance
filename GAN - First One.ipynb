{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # courtsey http://stackoverflow.com/users/190280/josh-bleecher-snyder\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Xt_Yt(X, y, percentage=0.9):\n",
    "    p = int(len(X) * percentage)\n",
    "    X_train = X[0:p]\n",
    "    Y_train = y[0:p]\n",
    "     \n",
    "    X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    " \n",
    "    X_test = X[p:]\n",
    "    Y_test = y[p:]\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_examples(data):\n",
    "    newX = []\n",
    "    for i in range(len(data)):\n",
    "        if np.isnan(data[i]).any() == False:\n",
    "            newX.append(data[i])\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers import Convolution1D, MaxPooling1D, Convolution1D, RepeatVector\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import *\n",
    "from keras.optimizers import RMSprop, Adam, SGD, Nadam\n",
    "from keras.initializers import *\n",
    "from keras.constraints import *\n",
    "\n",
    "from keras import backend as K\n",
    "import seaborn as sns\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2change(data):\n",
    "    change = pd.DataFrame(data).pct_change()\n",
    "    change = change.replace([np.inf, -np.inf], np.nan)\n",
    "    change = change.fillna(0.).values.tolist()\n",
    "    change = [c[0] for c in change]\n",
    "    return change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 5\n",
    "EMB_SIZE = 6\n",
    "STEP = 1\n",
    "FORECAST = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original = pd.read_csv('dataset/700_data_from_IB_1day.csv')[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "openp = data_original.loc[:, 'open'].tolist()\n",
    "highp = data_original.loc[:, 'high'].tolist()\n",
    "lowp = data_original.loc[:, 'low'].tolist()\n",
    "closep = data_original.loc[:, 'close'].tolist()\n",
    "volumep = data_original.loc[:, 'volume'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "openp = data2change(openp)\n",
    "highp = data2change(highp)\n",
    "lowp = data2change(lowp)\n",
    "closep = data2change(closep)\n",
    "volumep = data2change(volumep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "volatility = []\n",
    "for i in range(WINDOW, len(openp)):\n",
    "    window = highp[i-WINDOW:i]\n",
    "    volatility.append(np.std(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "openp, highp, lowp, closep, volumep = openp[WINDOW:], highp[WINDOW:], lowp[WINDOW:], closep[WINDOW:], volumep[WINDOW:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(volatility)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "for i in range(0, len(data_original), STEP): \n",
    "    try:\n",
    "        o = openp[i:i+WINDOW]\n",
    "        h = highp[i:i+WINDOW]\n",
    "        l = lowp[i:i+WINDOW]\n",
    "        c = closep[i:i+WINDOW]\n",
    "        v = volumep[i:i+WINDOW]\n",
    "\n",
    "        volat = volatility[i:i+WINDOW]\n",
    "\n",
    "        y_i = volatility[i+WINDOW+FORECAST] \n",
    "#        y_i = closep[i+WINDOW+FORECAST] \n",
    "        x_i = np.column_stack((volat, o, h, l, c, v))\n",
    "\n",
    "    except Exception as e:\n",
    "        break\n",
    "\n",
    "    X.append(x_i)\n",
    "    Y.append(y_i)\n",
    "\n",
    "X, Y = np.array(X), np.array(Y)\n",
    "X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \n",
    "    def shuffle_in_unison(a, b):\n",
    "        # courtsey http://stackoverflow.com/users/190280/josh-bleecher-snyder\n",
    "        assert len(a) == len(b)\n",
    "        shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "        shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "        permutation = np.random.permutation(len(a))\n",
    "        for old_index, new_index in enumerate(permutation):\n",
    "            shuffled_a[new_index] = a[old_index]\n",
    "            shuffled_b[new_index] = b[old_index]\n",
    "        return shuffled_a, shuffled_b\n",
    "\n",
    "    def create_Xt_Yt(X, y, percentage=0.9):\n",
    "        p = int(len(X) * percentage)\n",
    "        X_train = X[0:p]\n",
    "        Y_train = y[0:p]\n",
    "\n",
    "        X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    "\n",
    "        X_test = X[p:]\n",
    "        Y_test = y[p:]\n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test  \n",
    "    \n",
    "    def remove_nan_examples(data):\n",
    "        newX = []\n",
    "        for i in range(len(data)):\n",
    "            if np.isnan(data[i]).any() == False:\n",
    "                newX.append(data[i])\n",
    "        return newX\n",
    "    \n",
    "    def data2change(data):\n",
    "        change = pd.DataFrame(data).pct_change()\n",
    "        change = change.replace([np.inf, -np.inf], np.nan)\n",
    "        change = change.fillna(0.).values.tolist()\n",
    "        change = [c[0] for c in change]\n",
    "        return change\n",
    "\n",
    "    def dataReader(self):\n",
    "        \n",
    "        data_original = pd.read_csv('dataset/700_data_from_IB_1day.csv')[::-1]\n",
    "        \n",
    "        openp = data_original.loc[:, 'open'].tolist()\n",
    "        highp = data_original.loc[:, 'high'].tolist()\n",
    "        lowp = data_original.loc[:, 'low'].tolist()\n",
    "        closep = data_original.loc[:, 'close'].tolist()\n",
    "        volumep = data_original.loc[:, 'volume'].tolist()\n",
    "        \n",
    "        openp = data2change(openp)\n",
    "        highp = data2change(highp)\n",
    "        lowp = data2change(lowp)\n",
    "        closep = data2change(closep)\n",
    "        volumep = data2change(volumep)\n",
    "        \n",
    "        volatility = []\n",
    "        for i in range(WINDOW, len(openp)):\n",
    "            window = highp[i-WINDOW:i]\n",
    "            volatility.append(np.std(window))\n",
    "            \n",
    "        openp, highp, lowp, closep, volumep = openp[WINDOW:], highp[WINDOW:], lowp[WINDOW:], closep[WINDOW:], volumep[WINDOW:]\n",
    "        \n",
    "        X, Y = [], []\n",
    "        for i in range(0, len(data_original), STEP): \n",
    "            try:\n",
    "                o = openp[i:i+WINDOW]\n",
    "                h = highp[i:i+WINDOW]\n",
    "                l = lowp[i:i+WINDOW]\n",
    "                c = closep[i:i+WINDOW]\n",
    "                v = volumep[i:i+WINDOW]\n",
    "\n",
    "                volat = volatility[i:i+WINDOW]\n",
    "\n",
    "                y_i = volatility[i+WINDOW+FORECAST] \n",
    "        #        y_i = closep[i+WINDOW+FORECAST] \n",
    "                x_i = np.column_stack((volat, o, h, l, c, v))\n",
    "\n",
    "            except Exception as e:\n",
    "                break\n",
    "\n",
    "            X.append(x_i)\n",
    "            Y.append(y_i)\n",
    "\n",
    "        X, Y = np.array(X), np.array(Y)\n",
    "        X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y)\n",
    "        \n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))\n",
    "        \n",
    "        return X_train, X_test, Y_train, Y_test \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    \n",
    "    def shuffle_in_unison(a, b):\n",
    "        # courtsey http://stackoverflow.com/users/190280/josh-bleecher-snyder\n",
    "        assert len(a) == len(b)\n",
    "        shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "        shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "        permutation = np.random.permutation(len(a))\n",
    "        for old_index, new_index in enumerate(permutation):\n",
    "            shuffled_a[new_index] = a[old_index]\n",
    "            shuffled_b[new_index] = b[old_index]\n",
    "        return shuffled_a, shuffled_b\n",
    "    \n",
    "    def create_Xt_Yt(X, y, percentage=0.9):\n",
    "        p = int(len(X) * percentage)\n",
    "        X_train = X[0:p]\n",
    "        Y_train = y[0:p]\n",
    "\n",
    "        X_train, Y_train = shuffle_in_unison(X_train, Y_train)\n",
    "\n",
    "        X_test = X[p:]\n",
    "        Y_test = y[p:]\n",
    "\n",
    "        return X_train, X_test, Y_train, Y_test\n",
    "    \n",
    "    def remove_nan_examples(data):\n",
    "        newX = []\n",
    "        for i in range(len(data)):\n",
    "            if np.isnan(data[i]).any() == False:\n",
    "                newX.append(data[i])\n",
    "        return newX\n",
    "    \n",
    "    def data2change(data):\n",
    "        change = pd.DataFrame(data).pct_change()\n",
    "        change = change.replace([np.inf, -np.inf], np.nan)\n",
    "        change = change.fillna(0.).values.tolist()\n",
    "        change = [c[0] for c in change]\n",
    "        return change\n",
    "    \n",
    "    def dataReader(self):\n",
    "        \n",
    "        data_original = pd.read_csv('dataset/700_data_from_IB_1day.csv')[::-1]\n",
    "        \n",
    "        openp = data_original.loc[:, 'open'].tolist()\n",
    "        highp = data_original.loc[:, 'high'].tolist()\n",
    "        lowp = data_original.loc[:, 'low'].tolist()\n",
    "        closep = data_original.loc[:, 'close'].tolist()\n",
    "        volumep = data_original.loc[:, 'volume'].tolist()\n",
    "        \n",
    "        openp = data2change(openp)\n",
    "        highp = data2change(highp)\n",
    "        lowp = data2change(lowp)\n",
    "        closep = data2change(closep)\n",
    "        volumep = data2change(volumep)\n",
    "        \n",
    "        volatility = []\n",
    "        for i in range(WINDOW, len(openp)):\n",
    "            window = highp[i-WINDOW:i]\n",
    "            volatility.append(np.std(window))\n",
    "            \n",
    "        openp, highp, lowp, closep, volumep = openp[WINDOW:], highp[WINDOW:], lowp[WINDOW:], closep[WINDOW:], volumep[WINDOW:]\n",
    "        \n",
    "        X, Y = [], []\n",
    "        for i in range(0, len(data_original), STEP): \n",
    "            try:\n",
    "                o = openp[i:i+WINDOW]\n",
    "                h = highp[i:i+WINDOW]\n",
    "                l = lowp[i:i+WINDOW]\n",
    "                c = closep[i:i+WINDOW]\n",
    "                v = volumep[i:i+WINDOW]\n",
    "\n",
    "                volat = volatility[i:i+WINDOW]\n",
    "\n",
    "                y_i = volatility[i+WINDOW+FORECAST] \n",
    "        #        y_i = closep[i+WINDOW+FORECAST] \n",
    "                x_i = np.column_stack((volat, o, h, l, c, v))\n",
    "\n",
    "            except Exception as e:\n",
    "                break\n",
    "\n",
    "            X.append(x_i)\n",
    "            Y.append(y_i)\n",
    "\n",
    "        X, Y = np.array(X), np.array(Y)\n",
    "        X_train, X_test, Y_train, Y_test = create_Xt_Yt(X, Y)\n",
    "        \n",
    "        X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], EMB_SIZE))\n",
    "        X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], EMB_SIZE))\n",
    "        \n",
    "        return X_train, X_test, Y_train, Y_test \n",
    "        \n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.WINDOW = 5\n",
    "        self.EMB_SIZE = 6\n",
    "        self.STEP = 1\n",
    "        self.FORECAST = 1\n",
    "        \n",
    "        self.img_shape = (self.WINDOW, self.EMB_SIZE)\n",
    "        \n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.WINDOW, self.EMB_SIZE))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (self.WINDOW, self.EMB_SIZE)\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Convolution1D(input_shape = (self.WINDOW, self.EMB_SIZE),\n",
    "                        filters=16,\n",
    "                        kernel_size=4,\n",
    "                        padding='same'))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Convolution1D(filters=32,\n",
    "                                kernel_size=4,\n",
    "                                padding='same'))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(16))\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('linear'))\n",
    "\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "#        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        img_shape = (self.WINDOW, self.EMB_SIZE)\n",
    "        \n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Convolution1D(input_shape = (self.WINDOW, self.EMB_SIZE),\n",
    "                        filters=16,\n",
    "                        kernel_size=4,\n",
    "                        padding='same'))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Convolution1D(filters=32,\n",
    "                                kernel_size=4,\n",
    "                                padding='same'))\n",
    "        model.add(MaxPooling1D(2))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(Flatten())\n",
    "\n",
    "        model.add(Dense(16))\n",
    "        model.add(LeakyReLU())\n",
    "\n",
    "        model.add(Dense(1))\n",
    "        model.add(Activation('linear'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train, X_test, Y_train, Y_test = self.dataReader()\n",
    "      \n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, self.WINDOW, self.EMB_SIZE))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.WINDOW, self.EMB_SIZE))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch, batch_size)\n",
    "\n",
    "    def save_imgs(self, epoch, batch_size):\n",
    "\n",
    "        noise = np.random.normal(0, 1, (batch_size, self.WINDOW, self.EMB_SIZE))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        \n",
    "        #Reshape the data\n",
    "        gen_imgs = gen_imgs.reshape(-1,self.EMB_SIZE)\n",
    "\n",
    "        #Place it in DataFrame\n",
    "        gen_data = pd.DataFrame(gen_imgs)\n",
    "        gen_data.columns = ['volatility', 'open', 'high', 'low', 'close', 'volume']\n",
    "\n",
    "        #Plot the chart\n",
    "        fig = plt.plot(gen_data['volatility'])\n",
    "        plt.legend()\n",
    "        plt.savefig(\"gan/images/volatility_%d.png\" % epoch)\n",
    "#       plt.show(fig)\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 5, 16)             400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,025\n",
      "Trainable params: 3,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 5, 16)             400       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2, 32)             2080      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1, 32)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 17        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                60        \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 5, 6)              0         \n",
      "=================================================================\n",
      "Total params: 3,085\n",
      "Trainable params: 3,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "1 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "2 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "3 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "4 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "5 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "6 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "7 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "8 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "9 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "10 [D loss: 7.712474, acc.: 50.00%] [G loss: 15.424949]\n",
      "11 [D loss: 7.131847, acc.: 50.00%] [G loss: 15.424949]\n",
      "12 [D loss: 7.712578, acc.: 50.00%] [G loss: 15.424949]\n",
      "13 [D loss: 7.362896, acc.: 50.00%] [G loss: 14.843081]\n",
      "14 [D loss: 6.824375, acc.: 50.00%] [G loss: 9.630672]\n",
      "15 [D loss: 6.132904, acc.: 50.00%] [G loss: 4.332837]\n",
      "16 [D loss: 4.712684, acc.: 50.00%] [G loss: 3.669055]\n",
      "17 [D loss: 3.429808, acc.: 50.00%] [G loss: 3.488153]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 [D loss: 3.494173, acc.: 50.00%] [G loss: 3.356658]\n",
      "19 [D loss: 3.051546, acc.: 50.00%] [G loss: 3.256737]\n",
      "20 [D loss: 3.606242, acc.: 50.00%] [G loss: 3.210929]\n",
      "21 [D loss: 2.253821, acc.: 50.00%] [G loss: 3.004451]\n",
      "22 [D loss: 1.805803, acc.: 50.00%] [G loss: 2.947062]\n",
      "23 [D loss: 1.783574, acc.: 50.00%] [G loss: 2.912738]\n",
      "24 [D loss: 1.716120, acc.: 50.00%] [G loss: 2.835461]\n",
      "25 [D loss: 1.614907, acc.: 50.00%] [G loss: 2.803049]\n",
      "26 [D loss: 1.494111, acc.: 50.00%] [G loss: 2.803183]\n",
      "27 [D loss: 1.584151, acc.: 50.00%] [G loss: 2.789089]\n",
      "28 [D loss: 1.554301, acc.: 50.00%] [G loss: 2.723212]\n",
      "29 [D loss: 1.600179, acc.: 50.00%] [G loss: 2.719753]\n",
      "30 [D loss: 1.521456, acc.: 50.00%] [G loss: 2.731174]\n",
      "31 [D loss: 1.516961, acc.: 50.00%] [G loss: 2.681624]\n",
      "32 [D loss: 1.569885, acc.: 50.00%] [G loss: 2.684530]\n",
      "33 [D loss: 1.467154, acc.: 50.00%] [G loss: 2.664968]\n",
      "34 [D loss: 1.501495, acc.: 50.00%] [G loss: 2.632273]\n",
      "35 [D loss: 1.447029, acc.: 50.00%] [G loss: 2.600824]\n",
      "36 [D loss: 1.445954, acc.: 50.00%] [G loss: 2.629631]\n",
      "37 [D loss: 1.418814, acc.: 50.00%] [G loss: 2.606363]\n",
      "38 [D loss: 1.374086, acc.: 50.00%] [G loss: 2.598775]\n",
      "39 [D loss: 1.447118, acc.: 50.00%] [G loss: 2.609287]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 [D loss: 1.399132, acc.: 50.00%] [G loss: 2.569452]\n",
      "41 [D loss: 1.421414, acc.: 50.00%] [G loss: 2.547077]\n",
      "42 [D loss: 1.334609, acc.: 50.00%] [G loss: 2.535887]\n",
      "43 [D loss: 1.413516, acc.: 50.00%] [G loss: 2.544210]\n",
      "44 [D loss: 1.392887, acc.: 50.00%] [G loss: 2.546525]\n",
      "45 [D loss: 1.362137, acc.: 50.00%] [G loss: 2.513842]\n",
      "46 [D loss: 1.320681, acc.: 50.00%] [G loss: 2.536127]\n",
      "47 [D loss: 1.330164, acc.: 50.00%] [G loss: 2.507745]\n",
      "48 [D loss: 1.380056, acc.: 50.00%] [G loss: 2.503046]\n",
      "49 [D loss: 1.312388, acc.: 50.00%] [G loss: 2.496296]\n",
      "50 [D loss: 1.288326, acc.: 50.00%] [G loss: 2.484758]\n",
      "51 [D loss: 1.354628, acc.: 50.00%] [G loss: 2.486719]\n",
      "52 [D loss: 1.252309, acc.: 50.00%] [G loss: 2.478447]\n",
      "53 [D loss: 1.285582, acc.: 50.00%] [G loss: 2.476557]\n",
      "54 [D loss: 1.301203, acc.: 50.00%] [G loss: 2.477803]\n",
      "55 [D loss: 1.292351, acc.: 50.00%] [G loss: 2.454573]\n",
      "56 [D loss: 1.279279, acc.: 50.00%] [G loss: 2.445837]\n",
      "57 [D loss: 1.210469, acc.: 50.00%] [G loss: 2.440003]\n",
      "58 [D loss: 1.257836, acc.: 50.00%] [G loss: 2.432138]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 [D loss: 1.219664, acc.: 50.00%] [G loss: 2.435570]\n",
      "60 [D loss: 1.228846, acc.: 50.00%] [G loss: 2.415401]\n",
      "61 [D loss: 1.244264, acc.: 50.00%] [G loss: 2.409231]\n",
      "62 [D loss: 1.275067, acc.: 50.00%] [G loss: 2.401139]\n",
      "63 [D loss: 1.231501, acc.: 50.00%] [G loss: 2.397212]\n",
      "64 [D loss: 1.235867, acc.: 50.00%] [G loss: 2.389340]\n",
      "65 [D loss: 1.280533, acc.: 50.00%] [G loss: 2.380681]\n",
      "66 [D loss: 1.218263, acc.: 50.00%] [G loss: 2.371135]\n",
      "67 [D loss: 1.203104, acc.: 50.00%] [G loss: 2.360311]\n",
      "68 [D loss: 1.231130, acc.: 50.00%] [G loss: 2.352793]\n",
      "69 [D loss: 1.175310, acc.: 50.00%] [G loss: 2.350585]\n",
      "70 [D loss: 1.138771, acc.: 50.00%] [G loss: 2.339912]\n",
      "71 [D loss: 1.165778, acc.: 50.00%] [G loss: 2.333733]\n",
      "72 [D loss: 1.147627, acc.: 50.00%] [G loss: 2.330386]\n",
      "73 [D loss: 1.107678, acc.: 50.00%] [G loss: 2.322094]\n",
      "74 [D loss: 1.133265, acc.: 50.00%] [G loss: 2.321044]\n",
      "75 [D loss: 1.144551, acc.: 50.00%] [G loss: 2.315451]\n",
      "76 [D loss: 1.151848, acc.: 50.00%] [G loss: 2.302035]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77 [D loss: 1.101963, acc.: 50.00%] [G loss: 2.294809]\n",
      "78 [D loss: 1.107647, acc.: 50.00%] [G loss: 2.299465]\n",
      "79 [D loss: 1.139716, acc.: 50.00%] [G loss: 2.287050]\n",
      "80 [D loss: 1.116314, acc.: 50.00%] [G loss: 2.286327]\n",
      "81 [D loss: 1.128018, acc.: 50.00%] [G loss: 2.268785]\n",
      "82 [D loss: 1.151728, acc.: 50.00%] [G loss: 2.266448]\n",
      "83 [D loss: 1.126555, acc.: 50.00%] [G loss: 2.255758]\n",
      "84 [D loss: 1.160633, acc.: 50.00%] [G loss: 2.255451]\n",
      "85 [D loss: 1.101831, acc.: 50.00%] [G loss: 2.258909]\n",
      "86 [D loss: 1.085560, acc.: 50.00%] [G loss: 2.235718]\n",
      "87 [D loss: 1.120800, acc.: 50.00%] [G loss: 2.241124]\n",
      "88 [D loss: 1.105143, acc.: 50.00%] [G loss: 2.245074]\n",
      "89 [D loss: 1.092154, acc.: 50.00%] [G loss: 2.228997]\n",
      "90 [D loss: 1.043695, acc.: 50.00%] [G loss: 2.228201]\n",
      "91 [D loss: 1.035107, acc.: 50.00%] [G loss: 2.222991]\n",
      "92 [D loss: 1.025124, acc.: 50.00%] [G loss: 2.229136]\n",
      "93 [D loss: 1.004150, acc.: 50.00%] [G loss: 2.210199]\n",
      "94 [D loss: 0.957350, acc.: 50.00%] [G loss: 2.209148]\n",
      "95 [D loss: 1.008499, acc.: 50.00%] [G loss: 2.203232]\n",
      "96 [D loss: 1.017503, acc.: 50.00%] [G loss: 2.184658]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 [D loss: 1.003185, acc.: 50.00%] [G loss: 2.179173]\n",
      "98 [D loss: 1.014745, acc.: 50.00%] [G loss: 2.167225]\n",
      "99 [D loss: 1.059905, acc.: 50.00%] [G loss: 2.157328]\n",
      "100 [D loss: 1.023985, acc.: 50.00%] [G loss: 2.168902]\n",
      "101 [D loss: 1.004801, acc.: 50.00%] [G loss: 2.142818]\n",
      "102 [D loss: 0.956968, acc.: 50.00%] [G loss: 2.145285]\n",
      "103 [D loss: 0.975366, acc.: 50.00%] [G loss: 2.150692]\n",
      "104 [D loss: 1.021123, acc.: 50.00%] [G loss: 2.141853]\n",
      "105 [D loss: 1.026341, acc.: 50.00%] [G loss: 2.124287]\n",
      "106 [D loss: 0.975351, acc.: 50.00%] [G loss: 2.120980]\n",
      "107 [D loss: 0.982093, acc.: 50.00%] [G loss: 2.119503]\n",
      "108 [D loss: 0.998410, acc.: 50.00%] [G loss: 2.117960]\n",
      "109 [D loss: 0.963559, acc.: 50.00%] [G loss: 2.128712]\n",
      "110 [D loss: 0.976553, acc.: 50.00%] [G loss: 2.102289]\n",
      "111 [D loss: 0.995258, acc.: 50.00%] [G loss: 2.103755]\n",
      "112 [D loss: 0.969128, acc.: 50.00%] [G loss: 2.084074]\n",
      "113 [D loss: 0.941161, acc.: 50.00%] [G loss: 2.071624]\n",
      "114 [D loss: 0.948387, acc.: 50.00%] [G loss: 2.074320]\n",
      "115 [D loss: 0.989135, acc.: 50.00%] [G loss: 2.061331]\n",
      "116 [D loss: 0.989375, acc.: 50.00%] [G loss: 2.077912]\n",
      "117 [D loss: 0.995434, acc.: 50.00%] [G loss: 2.056216]\n",
      "118 [D loss: 0.976830, acc.: 50.00%] [G loss: 2.067539]\n",
      "119 [D loss: 0.964294, acc.: 50.00%] [G loss: 2.049773]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 [D loss: 0.893972, acc.: 50.00%] [G loss: 2.025398]\n",
      "121 [D loss: 0.960867, acc.: 50.00%] [G loss: 2.028578]\n",
      "122 [D loss: 0.883510, acc.: 50.00%] [G loss: 2.050828]\n",
      "123 [D loss: 0.904130, acc.: 50.00%] [G loss: 2.022210]\n",
      "124 [D loss: 0.839697, acc.: 50.00%] [G loss: 2.037068]\n",
      "125 [D loss: 0.834491, acc.: 50.00%] [G loss: 2.033758]\n",
      "126 [D loss: 0.927795, acc.: 50.00%] [G loss: 2.004464]\n",
      "127 [D loss: 0.854010, acc.: 50.00%] [G loss: 1.999800]\n",
      "128 [D loss: 0.932415, acc.: 50.00%] [G loss: 1.998840]\n",
      "129 [D loss: 0.931149, acc.: 50.00%] [G loss: 1.987887]\n",
      "130 [D loss: 0.874597, acc.: 50.00%] [G loss: 1.989771]\n",
      "131 [D loss: 0.927042, acc.: 50.00%] [G loss: 1.980378]\n",
      "132 [D loss: 0.846337, acc.: 50.00%] [G loss: 1.976590]\n",
      "133 [D loss: 0.884474, acc.: 50.00%] [G loss: 1.982944]\n",
      "134 [D loss: 0.857772, acc.: 50.00%] [G loss: 1.959050]\n",
      "135 [D loss: 0.893198, acc.: 50.00%] [G loss: 1.962435]\n",
      "136 [D loss: 0.838819, acc.: 50.00%] [G loss: 1.945282]\n",
      "137 [D loss: 0.859355, acc.: 50.00%] [G loss: 1.944921]\n",
      "138 [D loss: 0.821863, acc.: 50.00%] [G loss: 1.929878]\n",
      "139 [D loss: 0.819336, acc.: 50.00%] [G loss: 1.946708]\n",
      "140 [D loss: 0.832988, acc.: 50.00%] [G loss: 1.947870]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141 [D loss: 0.825229, acc.: 50.00%] [G loss: 1.931753]\n",
      "142 [D loss: 0.879345, acc.: 50.00%] [G loss: 1.933933]\n",
      "143 [D loss: 0.879370, acc.: 50.00%] [G loss: 1.921516]\n",
      "144 [D loss: 0.861522, acc.: 50.00%] [G loss: 1.908913]\n",
      "145 [D loss: 0.855730, acc.: 50.00%] [G loss: 1.904253]\n",
      "146 [D loss: 0.866603, acc.: 50.00%] [G loss: 1.895303]\n",
      "147 [D loss: 0.845205, acc.: 50.00%] [G loss: 1.891693]\n",
      "148 [D loss: 0.816404, acc.: 50.00%] [G loss: 1.894654]\n",
      "149 [D loss: 0.829632, acc.: 50.00%] [G loss: 1.884268]\n",
      "150 [D loss: 0.817245, acc.: 50.00%] [G loss: 1.878759]\n",
      "151 [D loss: 0.842215, acc.: 50.00%] [G loss: 1.864766]\n",
      "152 [D loss: 0.885760, acc.: 50.00%] [G loss: 1.864082]\n",
      "153 [D loss: 0.783210, acc.: 50.00%] [G loss: 1.849954]\n",
      "154 [D loss: 0.817900, acc.: 50.00%] [G loss: 1.861659]\n",
      "155 [D loss: 0.829735, acc.: 50.00%] [G loss: 1.845928]\n",
      "156 [D loss: 0.826726, acc.: 50.00%] [G loss: 1.847698]\n",
      "157 [D loss: 0.822941, acc.: 50.00%] [G loss: 1.833571]\n",
      "158 [D loss: 0.798980, acc.: 50.00%] [G loss: 1.829925]\n",
      "159 [D loss: 0.815358, acc.: 50.00%] [G loss: 1.845464]\n",
      "160 [D loss: 0.780010, acc.: 50.00%] [G loss: 1.829860]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161 [D loss: 0.797247, acc.: 50.00%] [G loss: 1.826094]\n",
      "162 [D loss: 0.784886, acc.: 50.00%] [G loss: 1.817502]\n",
      "163 [D loss: 0.847242, acc.: 50.00%] [G loss: 1.813909]\n",
      "164 [D loss: 0.792569, acc.: 50.00%] [G loss: 1.820885]\n",
      "165 [D loss: 0.729154, acc.: 50.00%] [G loss: 1.814983]\n",
      "166 [D loss: 0.747268, acc.: 50.00%] [G loss: 1.801624]\n",
      "167 [D loss: 0.783940, acc.: 50.00%] [G loss: 1.802682]\n",
      "168 [D loss: 0.742205, acc.: 53.12%] [G loss: 1.783971]\n",
      "169 [D loss: 0.777717, acc.: 50.00%] [G loss: 1.782955]\n",
      "170 [D loss: 0.830053, acc.: 50.00%] [G loss: 1.781693]\n",
      "171 [D loss: 0.781130, acc.: 50.00%] [G loss: 1.784506]\n",
      "172 [D loss: 0.743463, acc.: 56.25%] [G loss: 1.775480]\n",
      "173 [D loss: 0.776385, acc.: 50.00%] [G loss: 1.766589]\n",
      "174 [D loss: 0.782587, acc.: 50.00%] [G loss: 1.761550]\n",
      "175 [D loss: 0.693634, acc.: 53.12%] [G loss: 1.760102]\n",
      "176 [D loss: 0.798356, acc.: 50.00%] [G loss: 1.758300]\n",
      "177 [D loss: 0.737914, acc.: 53.12%] [G loss: 1.763275]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 [D loss: 0.760502, acc.: 50.00%] [G loss: 1.746613]\n",
      "179 [D loss: 0.737985, acc.: 50.00%] [G loss: 1.749323]\n",
      "180 [D loss: 0.757352, acc.: 50.00%] [G loss: 1.747149]\n",
      "181 [D loss: 0.724658, acc.: 50.00%] [G loss: 1.739163]\n",
      "182 [D loss: 0.753750, acc.: 50.00%] [G loss: 1.727432]\n",
      "183 [D loss: 0.738751, acc.: 50.00%] [G loss: 1.733009]\n",
      "184 [D loss: 0.699410, acc.: 53.12%] [G loss: 1.723379]\n",
      "185 [D loss: 0.773283, acc.: 50.00%] [G loss: 1.720503]\n",
      "186 [D loss: 0.735261, acc.: 50.00%] [G loss: 1.710310]\n",
      "187 [D loss: 0.769848, acc.: 50.00%] [G loss: 1.712890]\n",
      "188 [D loss: 0.742356, acc.: 50.00%] [G loss: 1.706553]\n",
      "189 [D loss: 0.784987, acc.: 50.00%] [G loss: 1.701800]\n",
      "190 [D loss: 0.691981, acc.: 56.25%] [G loss: 1.699503]\n",
      "191 [D loss: 0.763675, acc.: 53.12%] [G loss: 1.696547]\n",
      "192 [D loss: 0.779785, acc.: 53.12%] [G loss: 1.692224]\n",
      "193 [D loss: 0.723029, acc.: 53.12%] [G loss: 1.691468]\n",
      "194 [D loss: 0.697090, acc.: 53.12%] [G loss: 1.678957]\n",
      "195 [D loss: 0.702313, acc.: 50.00%] [G loss: 1.682043]\n",
      "196 [D loss: 0.743237, acc.: 50.00%] [G loss: 1.676344]\n",
      "197 [D loss: 0.697225, acc.: 50.00%] [G loss: 1.675421]\n",
      "198 [D loss: 0.693098, acc.: 50.00%] [G loss: 1.674309]\n",
      "199 [D loss: 0.742177, acc.: 50.00%] [G loss: 1.662437]\n",
      "200 [D loss: 0.661823, acc.: 59.38%] [G loss: 1.664095]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201 [D loss: 0.717523, acc.: 50.00%] [G loss: 1.659771]\n",
      "202 [D loss: 0.700198, acc.: 53.12%] [G loss: 1.653502]\n",
      "203 [D loss: 0.747273, acc.: 50.00%] [G loss: 1.651912]\n",
      "204 [D loss: 0.770957, acc.: 53.12%] [G loss: 1.643302]\n",
      "205 [D loss: 0.677602, acc.: 53.12%] [G loss: 1.639922]\n",
      "206 [D loss: 0.759960, acc.: 50.00%] [G loss: 1.637527]\n",
      "207 [D loss: 0.690216, acc.: 53.12%] [G loss: 1.631985]\n",
      "208 [D loss: 0.773145, acc.: 53.12%] [G loss: 1.626579]\n",
      "209 [D loss: 0.710640, acc.: 50.00%] [G loss: 1.626514]\n",
      "210 [D loss: 0.686498, acc.: 53.12%] [G loss: 1.623759]\n",
      "211 [D loss: 0.707383, acc.: 53.12%] [G loss: 1.621976]\n",
      "212 [D loss: 0.660418, acc.: 56.25%] [G loss: 1.613436]\n",
      "213 [D loss: 0.733630, acc.: 50.00%] [G loss: 1.612804]\n",
      "214 [D loss: 0.693358, acc.: 53.12%] [G loss: 1.601382]\n",
      "215 [D loss: 0.717030, acc.: 56.25%] [G loss: 1.604728]\n",
      "216 [D loss: 0.715473, acc.: 53.12%] [G loss: 1.596525]\n",
      "217 [D loss: 0.676666, acc.: 59.38%] [G loss: 1.590994]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 [D loss: 0.746350, acc.: 50.00%] [G loss: 1.596879]\n",
      "219 [D loss: 0.662245, acc.: 53.12%] [G loss: 1.581079]\n",
      "220 [D loss: 0.695831, acc.: 56.25%] [G loss: 1.579455]\n",
      "221 [D loss: 0.675605, acc.: 53.12%] [G loss: 1.578992]\n",
      "222 [D loss: 0.720629, acc.: 50.00%] [G loss: 1.576931]\n",
      "223 [D loss: 0.688803, acc.: 53.12%] [G loss: 1.558885]\n",
      "224 [D loss: 0.688146, acc.: 53.12%] [G loss: 1.559804]\n",
      "225 [D loss: 0.651353, acc.: 62.50%] [G loss: 1.556881]\n",
      "226 [D loss: 0.614516, acc.: 59.38%] [G loss: 1.555098]\n",
      "227 [D loss: 0.665006, acc.: 50.00%] [G loss: 1.552364]\n",
      "228 [D loss: 0.669297, acc.: 56.25%] [G loss: 1.545536]\n",
      "229 [D loss: 0.644412, acc.: 56.25%] [G loss: 1.547527]\n",
      "230 [D loss: 0.664082, acc.: 53.12%] [G loss: 1.533570]\n",
      "231 [D loss: 0.676655, acc.: 53.12%] [G loss: 1.531825]\n",
      "232 [D loss: 0.650669, acc.: 62.50%] [G loss: 1.530433]\n",
      "233 [D loss: 0.685423, acc.: 50.00%] [G loss: 1.514789]\n",
      "234 [D loss: 0.683449, acc.: 50.00%] [G loss: 1.510087]\n",
      "235 [D loss: 0.649565, acc.: 56.25%] [G loss: 1.522139]\n",
      "236 [D loss: 0.688643, acc.: 50.00%] [G loss: 1.502540]\n",
      "237 [D loss: 0.643784, acc.: 53.12%] [G loss: 1.506245]\n",
      "238 [D loss: 0.657572, acc.: 50.00%] [G loss: 1.499609]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239 [D loss: 0.668023, acc.: 53.12%] [G loss: 1.500738]\n",
      "240 [D loss: 0.695305, acc.: 50.00%] [G loss: 1.476689]\n",
      "241 [D loss: 0.668094, acc.: 59.38%] [G loss: 1.485898]\n",
      "242 [D loss: 0.597501, acc.: 59.38%] [G loss: 1.472097]\n",
      "243 [D loss: 0.661760, acc.: 53.12%] [G loss: 1.470125]\n",
      "244 [D loss: 0.671926, acc.: 53.12%] [G loss: 1.465858]\n",
      "245 [D loss: 0.632394, acc.: 62.50%] [G loss: 1.425328]\n",
      "246 [D loss: 0.638811, acc.: 53.12%] [G loss: 1.453797]\n",
      "247 [D loss: 0.663731, acc.: 53.12%] [G loss: 1.423149]\n",
      "248 [D loss: 0.635833, acc.: 56.25%] [G loss: 1.424897]\n",
      "249 [D loss: 0.682150, acc.: 50.00%] [G loss: 1.412390]\n",
      "250 [D loss: 0.616422, acc.: 56.25%] [G loss: 1.397923]\n",
      "251 [D loss: 0.639163, acc.: 56.25%] [G loss: 1.402391]\n",
      "252 [D loss: 0.694290, acc.: 53.12%] [G loss: 1.413834]\n",
      "253 [D loss: 0.647284, acc.: 53.12%] [G loss: 1.367767]\n",
      "254 [D loss: 0.598459, acc.: 65.62%] [G loss: 1.375227]\n",
      "255 [D loss: 0.676249, acc.: 50.00%] [G loss: 1.355567]\n",
      "256 [D loss: 0.656246, acc.: 53.12%] [G loss: 1.346459]\n",
      "257 [D loss: 0.666938, acc.: 53.12%] [G loss: 1.328348]\n",
      "258 [D loss: 0.653485, acc.: 56.25%] [G loss: 1.312964]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 [D loss: 0.628940, acc.: 62.50%] [G loss: 1.287619]\n",
      "260 [D loss: 0.720794, acc.: 50.00%] [G loss: 1.272693]\n",
      "261 [D loss: 0.685069, acc.: 53.12%] [G loss: 1.183928]\n",
      "262 [D loss: 0.700143, acc.: 50.00%] [G loss: 1.191704]\n",
      "263 [D loss: 0.652180, acc.: 59.38%] [G loss: 1.185998]\n",
      "264 [D loss: 0.656720, acc.: 56.25%] [G loss: 1.166561]\n",
      "265 [D loss: 0.692965, acc.: 56.25%] [G loss: 1.096553]\n",
      "266 [D loss: 0.708386, acc.: 53.12%] [G loss: 1.123423]\n",
      "267 [D loss: 0.648574, acc.: 59.38%] [G loss: 1.089087]\n",
      "268 [D loss: 0.664145, acc.: 62.50%] [G loss: 1.096855]\n",
      "269 [D loss: 0.655660, acc.: 59.38%] [G loss: 1.080492]\n",
      "270 [D loss: 0.664304, acc.: 59.38%] [G loss: 1.074812]\n",
      "271 [D loss: 0.684898, acc.: 56.25%] [G loss: 1.095627]\n",
      "272 [D loss: 0.692663, acc.: 56.25%] [G loss: 1.127405]\n",
      "273 [D loss: 0.653016, acc.: 59.38%] [G loss: 1.129997]\n",
      "274 [D loss: 0.628892, acc.: 56.25%] [G loss: 1.122390]\n",
      "275 [D loss: 0.694672, acc.: 53.12%] [G loss: 1.138115]\n",
      "276 [D loss: 0.599876, acc.: 71.88%] [G loss: 1.142988]\n",
      "277 [D loss: 0.674744, acc.: 50.00%] [G loss: 1.185321]\n",
      "278 [D loss: 0.631009, acc.: 62.50%] [G loss: 1.202799]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279 [D loss: 0.636716, acc.: 59.38%] [G loss: 1.244489]\n",
      "280 [D loss: 0.627582, acc.: 59.38%] [G loss: 1.298998]\n",
      "281 [D loss: 0.564134, acc.: 68.75%] [G loss: 1.335318]\n",
      "282 [D loss: 0.616562, acc.: 50.00%] [G loss: 1.378084]\n",
      "283 [D loss: 0.591814, acc.: 56.25%] [G loss: 1.422802]\n",
      "284 [D loss: 0.585810, acc.: 62.50%] [G loss: 1.460826]\n",
      "285 [D loss: 0.556972, acc.: 59.38%] [G loss: 1.496505]\n",
      "286 [D loss: 0.599684, acc.: 59.38%] [G loss: 1.539040]\n",
      "287 [D loss: 0.564711, acc.: 56.25%] [G loss: 1.572609]\n",
      "288 [D loss: 0.543895, acc.: 65.62%] [G loss: 1.625456]\n",
      "289 [D loss: 0.533312, acc.: 65.62%] [G loss: 1.646909]\n",
      "290 [D loss: 0.546853, acc.: 62.50%] [G loss: 1.681378]\n",
      "291 [D loss: 0.563794, acc.: 53.12%] [G loss: 1.672676]\n",
      "292 [D loss: 0.513541, acc.: 65.62%] [G loss: 1.694610]\n",
      "293 [D loss: 0.507816, acc.: 68.75%] [G loss: 1.722679]\n",
      "294 [D loss: 0.544443, acc.: 62.50%] [G loss: 1.701484]\n",
      "295 [D loss: 0.540501, acc.: 62.50%] [G loss: 1.681068]\n",
      "296 [D loss: 0.595891, acc.: 56.25%] [G loss: 1.721410]\n",
      "297 [D loss: 0.533797, acc.: 59.38%] [G loss: 1.634657]\n",
      "298 [D loss: 0.544611, acc.: 59.38%] [G loss: 1.619586]\n",
      "299 [D loss: 0.472135, acc.: 71.88%] [G loss: 1.619825]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    data = Data()\n",
    "    data = data.dataReader()\n",
    "    gan = GAN()\n",
    "    gan.train( epochs=300, batch_size=32, save_interval=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
